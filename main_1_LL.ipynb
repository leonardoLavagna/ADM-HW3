{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76bc6156",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98d4bc9",
   "metadata": {},
   "source": [
    "Our goal is to build a search engine over the \"Top Anime Series\" from the list of MyAnimeList https://myanimelist.net. There is no provided dataset, so we create our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8a0881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import requests\n",
    "import codecs\n",
    "import lxml\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444fc270",
   "metadata": {},
   "source": [
    "## 1. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17b994d",
   "metadata": {},
   "source": [
    "We start from the list of animes to include in the corpus of documents the search engine will work on. In particular, we focus on the top animes ever list: https://myanimelist.net/topanime.php.  The list is long and splitted in many pages. The first thing we will do is to retrieve the urls (and the names) of the animes listed in the first 400 pages (each page has 50 animes so you will end up with 20000 unique anime urls)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6770733b",
   "metadata": {},
   "source": [
    "### 1.1 Get the list of animes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be20482",
   "metadata": {},
   "source": [
    "Here we will extract the *urls* and the *names* of the animes in the list. At first we can have an idea of the necessary steps to extract the informations we want by working on a single anime in the list and then proceed by iteration. \n",
    "\n",
    "After inspecting the HTML code of the site, we saw that the all the informations we need from a single anime are stored in  `tr` blocks inside a single `table` that contains the list of all the top animes in the site. To get the  name of an anime in the list we should work on `a` tags, whereas to get the url we need to work on `td` tags (leveraging the property `href`). \n",
    "\n",
    "Knowing these HTML details we can use the `BeautifulSoup` library to do the web-scrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa49114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXECUTE ONLY ONCE\n",
    "# IF THE FILE links.txt EXISTS THEN DO NOT EXECUTE THIS CELL\n",
    "\n",
    "# REMARK: the execution can take some time (some minutes)\n",
    "\n",
    "# open an empty .txt file to store the urls we need\n",
    "links_text = open(\"links.txt\", \"w\")\n",
    "\n",
    "# go page by page in the site and scrap the urls we need\n",
    "for page in tqdm(range(0, 400)):\n",
    "    url = 'https://myanimelist.net/topanime.php?limit=' + str(page * 50)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    for tag in soup.find_all('tr'):\n",
    "        links = tag.find_all('a')\n",
    "        for link in links:        \n",
    "            if type(link.get('id')) == str and len(link.contents[0]) > 1:\n",
    "                data = link.get('href')\n",
    "                # write the scrapped urls in the .txt file with '\\n' at the end of each raw\n",
    "                links_text.write(data)\n",
    "                links_text.write(\"\\n\")\n",
    "\n",
    "# close the .txt file\n",
    "links_text.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5089af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the number of lines in the .txt file\n",
    "file = open(\"links.txt\", \"r\")\n",
    "line_count = 0\n",
    "for line in file:\n",
    "    if line != \"\\n\":\n",
    "        line_count += 1\n",
    "file.close()\n",
    "\n",
    "print('There are total {} lines in this file.'.format(line_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461f09ed",
   "metadata": {},
   "source": [
    "## 1.2 Crawl animes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bb39d3",
   "metadata": {},
   "source": [
    "We procede to:\n",
    "- download the html corresponding to each of the collected urls;\n",
    "- save its html in a file;\n",
    "- organize the entire set of downloaded html pages into folders. Each folder will contain the htmls of the animes in page 1, page 2, ... of the list of animes.\n",
    "\n",
    "To do so we extensively use the `os` library to create directories, changing paths, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0846fbbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EXECUTE ONLY ONCE\n",
    "# IF THE DIRECTORY TREE ALREADY EXISTS THEN DO NOT EXECUTE THIS CELL\n",
    "\n",
    "# REMARK: the execution can take quite some time (>25 hours)\n",
    "# REMARK: there is an issue with high frequency site-connections that blocks most of the page requests \n",
    "# a time delay between page requests has been included to solve that issue\n",
    "\n",
    "\n",
    "file = open(\"links.txt\", \"r\")\n",
    "lines = file.read().split('\\n')\n",
    "file.close()\n",
    "# returns current working directory\n",
    "base = os.getcwd()  \n",
    "# initialize the number of the first directory to be created\n",
    "t = 0\n",
    "# we use the previously created list of lines to get the urls we need\n",
    "scrapped_urls = lines[0:-1]\n",
    "for i in range(len(scrapped_urls)):\n",
    "    if(i%50==0):\n",
    "        # create a new folder\n",
    "        # remark: the newley created pages will start from 0\n",
    "        page_identifier = i-(49*t)\n",
    "        # subdirectory \n",
    "        directory = f\"page_{page_identifier}.html\"\n",
    "        # parent directories\n",
    "        parent_dir = base\n",
    "        # path\n",
    "        path = os.path.join(parent_dir, directory)\n",
    "        # make directory\n",
    "        os.makedirs(path)\n",
    "        # checkpoint\n",
    "        # print(\"Directory '%s' created\" %directory)\n",
    "        # change directory \n",
    "        os.chdir(path)\n",
    "        t += 1\n",
    "\n",
    "    # to avoid the issue with high frequency site-connections  \n",
    "    time.sleep(5)   \n",
    "\n",
    "    # get urls\n",
    "    URL = scrapped_urls[i]\n",
    "    page = requests.get(URL)\n",
    "    \n",
    "    # parsing\n",
    "    soup_data = BeautifulSoup(page.content, \"html.parser\")\n",
    "    \n",
    "    # saving\n",
    "    with open(f\"article_{i}.html\", \"w\") as file:\n",
    "        file.write(str(soup_data))\n",
    "        \n",
    "    # checkpoint\n",
    "    # print(f\"Article {i} successfully written!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dbdc2e",
   "metadata": {},
   "source": [
    "## 1.3 Parse downloaded pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29ab9ff",
   "metadata": {},
   "source": [
    "At this point we have all the html documents about the animes of interest and we can start to extract the animes informations:\n",
    "- Anime Name (to save as `animeTitle`): String\n",
    "-Anime Type (to save as `animeType`): String\n",
    "-Number of episode (to save as `animeNumEpisode`): Integer\n",
    "-Release and End Dates of anime (to save as `releaseDate` and `endDate`): Convert both release and end date into datetime format.\n",
    "-Number of members (to save as `animeNumMembers`): Integer\n",
    "-Score (to save as `animeScore`): Float\n",
    "-Users (to save as `animeUsers`): Integer\n",
    "-Rank (to save as `animeRank`): Integer\n",
    "-Popularity (to save as `animePopularity`): Integer\n",
    "-Synopsis (to save as `animeDescription`): String\n",
    "-Related Anime (to save as `animeRelated`): Extract all the related animes, but only keep unique values and those that have a hyperlink associated to them. List of strings.\n",
    "-Characters (to save as `animeCharacters`): List of strings.\n",
    "-Voices (to save as `animeVoices`): List of strings\n",
    "-Staff (to save as `animeStaff`): Include the staff name and their responsibility/task in a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace1498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "animeTitle = []\n",
    "animeType = []\n",
    "animeNumEpisode = []\n",
    "releaseDate = []\n",
    "endDate = []\n",
    "animeNumMembers = []\n",
    "animeScore = []\n",
    "animeUsers = []\n",
    "animeRank = []\n",
    "animePopularity = []\n",
    "animeDescription = []\n",
    "animeRelated = []\n",
    "animeCharacters = []\n",
    "animeVoices = []\n",
    "animeStaff = []\n",
    "\n",
    "# put the number of pages (total number of pages +1) instead of 2 in the outer for loop\n",
    "for j in range(2):\n",
    "    for i in range(50):\n",
    "        path = \"html_pages/\"+ \"page_\"+str(j)+\".html/article_\" + str(50*j+i) + \".html\"\n",
    "        file = codecs.open(path, \"r\", \"utf-8\")\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "        animeTitle.append(soup.find_all('strong')[0].contents[0])\n",
    "\n",
    "        divs = soup.find_all(\"div\", {\"class\": \"spaceit_pad\"})\n",
    "        for div in divs:\n",
    "            spans = div.find_all(\"span\")\n",
    "            for span in spans:\n",
    "\n",
    "                # TYPES\n",
    "                if span.contents[0] == 'Type:':\n",
    "                    animeType.append(div.find_all('a')[0].contents[0])\n",
    "\n",
    "                # NUMBER OF EPISODES\n",
    "                if span.contents[0] == 'Episodes:':\n",
    "                    try: \n",
    "                        animeNumEpisode.append(int(div.contents[2]))\n",
    "                    except:\n",
    "                        animeNumEpisode.append(0)\n",
    "\n",
    "\n",
    "        divs = soup.find_all(\"div\", {\"class\": \"stats-block po-r clearfix\"})\n",
    "        for div in divs:\n",
    "\n",
    "            # MEMBERS\n",
    "            members = div.find_all(\"span\", {\"class\": \"numbers members\"})\n",
    "            animeNumMembers.append(int(members[0].contents[1].contents[0].replace(',', '')))\n",
    "\n",
    "            # USERS\n",
    "            users = div.find_all(\"div\", {\"class\": \"fl-l score\"})\n",
    "            # here we we eliminate the word 'user '   \n",
    "            # that is why there is the [:-6] part\n",
    "            # we also replace the comma divisor\n",
    "            try:\n",
    "                animeUsers.append(int(users[0]['data-user'][:-6].replace(',', '')))\n",
    "            except:\n",
    "                animeUsers.append(0)\n",
    "\n",
    "            # SCORE\n",
    "            # center of the html page\n",
    "            rating=soup.find(name=\"div\",attrs={\"class\":\"fl-l score\"})\n",
    "            try:        \n",
    "                animeScore.append(float(rating.text.strip()))\n",
    "            except:\n",
    "                animeScore.append(None)\n",
    "\n",
    "            # RANK\n",
    "            rank = div.find_all(\"span\", {\"class\": \"numbers ranked\"})\n",
    "            animeRank.append(int(rank[0].contents[1].contents[0][1:]))\n",
    "\n",
    "            # POPULARITY\n",
    "            popularity = div.find_all(\"span\", {\"class\": \"numbers popularity\"})\n",
    "            animePopularity.append(int(popularity[0].contents[1].contents[0][1:]))\n",
    "\n",
    "        # DESCRIPTION\n",
    "        animeDescription = soup.find_all(\"p\", itemprop = \"description\")[0].text.strip().replace('\\n', '').replace('  ', '')\n",
    "\n",
    "        # RELATED \n",
    "        related = soup.find_all(\"table\", {\"class\": \"anime_detail_related_anime\"})\n",
    "        x = []\n",
    "        y = []\n",
    "        for tr in related:\n",
    "            td = tr.find_all(\"td\")\n",
    "            for i in range(0, len(td), 2):\n",
    "                x.append(td[i].contents[0])\n",
    "                try:\n",
    "                    t = td[i+1].find_all(\"a\")\n",
    "                    y.append(t[0].contents[0])\n",
    "                except:\n",
    "                    y.append('NA')\n",
    "\n",
    "            animeRelated.append('\\n'.join([f'{x} {y}' for x, y in dict(zip(x, y)).items()]).split('\\n'))\n",
    "\n",
    "        # CHARACTERS\n",
    "        try:\n",
    "            characters = soup.find_all(\"div\", {\"class\": \"detail-characters-list clearfix\"})\n",
    "            chars = characters[0].find_all(\"h3\", {\"class\": \"h3_characters_voice_actors\"})\n",
    "            x = []\n",
    "            for i in chars:\n",
    "                x.append(i.contents[0].contents[0])\n",
    "            animeCharacters.append(x)\n",
    "        except:\n",
    "            animeCharacters.append(\"NA\")\n",
    "\n",
    "        # VOICES\n",
    "        try:\n",
    "            voices = characters[0].find_all(\"td\", {\"class\": \"va-t ar pl4 pr4\"})\n",
    "            y = []\n",
    "            for i in voices:\n",
    "                y.append(i.contents[1].contents[0])\n",
    "            animeVoices.append(y)\n",
    "        except:\n",
    "            animeVoices.append(\"NA\")\n",
    "\n",
    "        # STAFF\n",
    "        try:\n",
    "            staff = soup.find_all(\"div\", {\"class\": \"detail-characters-list clearfix\"})\n",
    "            staff = staff[1].find_all(\"td\")\n",
    "            x = []\n",
    "            y = []\n",
    "            for i in range(1, len(staff), 2):\n",
    "                x.append(staff[i].contents[1].contents[0])\n",
    "                y.append(staff[i].find_all(\"small\")[0].contents[0])\n",
    "            animeStaff.append([list(i) for i in list(zip(x,y))])\n",
    "        except:\n",
    "            animeStaff.append(\"NA\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2340e5f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(\n",
    "    [animeTitle, animeType, animeNumEpisode, animeNumMembers, \n",
    "     animeScore, animeUsers, animeRank, animePopularity, animeDescription, animeRelated, \n",
    "     animeCharacters, animeVoices, animeStaff], \n",
    "    index=['Title', 'Type', 'Episodes', 'Members', 'Score', \n",
    "           'Users', 'Rank', 'Popularity', 'Description', 'Related', 'Characters', 'Voices', 'Staff']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16301ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Type</th>\n",
       "      <th>Episodes</th>\n",
       "      <th>Members</th>\n",
       "      <th>Score</th>\n",
       "      <th>Users</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Description</th>\n",
       "      <th>Related</th>\n",
       "      <th>Characters</th>\n",
       "      <th>Voices</th>\n",
       "      <th>Staff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>TV</td>\n",
       "      <td>64</td>\n",
       "      <td>2675751</td>\n",
       "      <td>9.16</td>\n",
       "      <td>1622384</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "      <td>[Adaptation: Fullmetal Alchemist, Alternative ...</td>\n",
       "      <td>[Elric, Edward, Elric, Alphonse, Mustang, Roy,...</td>\n",
       "      <td>[Park, Romi, Kugimiya, Rie, Miki, Shinichiro, ...</td>\n",
       "      <td>[[Cook, Justin, Producer], [Yonai, Noritomo, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gintama°</td>\n",
       "      <td>TV</td>\n",
       "      <td>51</td>\n",
       "      <td>483807</td>\n",
       "      <td>9.09</td>\n",
       "      <td>169476</td>\n",
       "      <td>2</td>\n",
       "      <td>337</td>\n",
       "      <td>e</td>\n",
       "      <td>[Adaptation: Gintama, Prequel: Gintama Movie 2...</td>\n",
       "      <td>[Sakata, Gintoki, Kagura, Shimura, Shinpachi, ...</td>\n",
       "      <td>[Sugita, Tomokazu, Kugimiya, Rie, Sakaguchi, D...</td>\n",
       "      <td>[[Fujita, Youichi, Director, Storyboard, Plann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shingeki no Kyojin Season 3 Part 2</td>\n",
       "      <td>TV</td>\n",
       "      <td>10</td>\n",
       "      <td>1596039</td>\n",
       "      <td>9.09</td>\n",
       "      <td>1087519</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>n</td>\n",
       "      <td>[Adaptation: Shingeki no Kyojin, Prequel: Shin...</td>\n",
       "      <td>[Levi, Yeager, Eren, Ackerman, Mikasa, Arlert,...</td>\n",
       "      <td>[Kamiya, Hiroshi, Kaji, Yuki, Ishikawa, Yui, I...</td>\n",
       "      <td>[[Yabuta, Shuuhei, Producer], [Wada, Jouji, Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>TV</td>\n",
       "      <td>24</td>\n",
       "      <td>2090910</td>\n",
       "      <td>9.09</td>\n",
       "      <td>1109700</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>t</td>\n",
       "      <td>[Adaptation: Steins;Gate, Alternative setting:...</td>\n",
       "      <td>[Okabe, Rintarou, Makise, Kurisu, Shiina, Mayu...</td>\n",
       "      <td>[Miyano, Mamoru, Imai, Asami, Hanazawa, Kana, ...</td>\n",
       "      <td>[[Iwasa, Gaku, Producer], [Yasuda, Takeshi, Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fruits Basket: The Final</td>\n",
       "      <td>TV</td>\n",
       "      <td>13</td>\n",
       "      <td>275214</td>\n",
       "      <td>9.07</td>\n",
       "      <td>113310</td>\n",
       "      <td>5</td>\n",
       "      <td>651</td>\n",
       "      <td>u</td>\n",
       "      <td>[Adaptation: Fruits Basket, Prequel: Fruits Ba...</td>\n",
       "      <td>[Souma, Kyou, Honda, Tooru, Souma, Yuki, Souma...</td>\n",
       "      <td>[Uchida, Yuuma, Iwami, Manaka, Shimazaki, Nobu...</td>\n",
       "      <td>[[Ibata, Yoshihide, Director], [Aketagawa, Jin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Title Type Episodes  Members Score    Users  \\\n",
       "0    Fullmetal Alchemist: Brotherhood   TV       64  2675751  9.16  1622384   \n",
       "1                            Gintama°   TV       51   483807  9.09   169476   \n",
       "2  Shingeki no Kyojin Season 3 Part 2   TV       10  1596039  9.09  1087519   \n",
       "3                         Steins;Gate   TV       24  2090910  9.09  1109700   \n",
       "4            Fruits Basket: The Final   TV       13   275214  9.07   113310   \n",
       "\n",
       "  Rank Popularity Description  \\\n",
       "0    1          3           C   \n",
       "1    2        337           e   \n",
       "2    3         33           n   \n",
       "3    4         11           t   \n",
       "4    5        651           u   \n",
       "\n",
       "                                             Related  \\\n",
       "0  [Adaptation: Fullmetal Alchemist, Alternative ...   \n",
       "1  [Adaptation: Gintama, Prequel: Gintama Movie 2...   \n",
       "2  [Adaptation: Shingeki no Kyojin, Prequel: Shin...   \n",
       "3  [Adaptation: Steins;Gate, Alternative setting:...   \n",
       "4  [Adaptation: Fruits Basket, Prequel: Fruits Ba...   \n",
       "\n",
       "                                          Characters  \\\n",
       "0  [Elric, Edward, Elric, Alphonse, Mustang, Roy,...   \n",
       "1  [Sakata, Gintoki, Kagura, Shimura, Shinpachi, ...   \n",
       "2  [Levi, Yeager, Eren, Ackerman, Mikasa, Arlert,...   \n",
       "3  [Okabe, Rintarou, Makise, Kurisu, Shiina, Mayu...   \n",
       "4  [Souma, Kyou, Honda, Tooru, Souma, Yuki, Souma...   \n",
       "\n",
       "                                              Voices  \\\n",
       "0  [Park, Romi, Kugimiya, Rie, Miki, Shinichiro, ...   \n",
       "1  [Sugita, Tomokazu, Kugimiya, Rie, Sakaguchi, D...   \n",
       "2  [Kamiya, Hiroshi, Kaji, Yuki, Ishikawa, Yui, I...   \n",
       "3  [Miyano, Mamoru, Imai, Asami, Hanazawa, Kana, ...   \n",
       "4  [Uchida, Yuuma, Iwami, Manaka, Shimazaki, Nobu...   \n",
       "\n",
       "                                               Staff  \n",
       "0  [[Cook, Justin, Producer], [Yonai, Noritomo, P...  \n",
       "1  [[Fujita, Youichi, Director, Storyboard, Plann...  \n",
       "2  [[Yabuta, Shuuhei, Producer], [Wada, Jouji, Pr...  \n",
       "3  [[Iwasa, Gaku, Producer], [Yasuda, Takeshi, Pr...  \n",
       "4  [[Ibata, Yoshihide, Director], [Aketagawa, Jin...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad5b0ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Type</th>\n",
       "      <th>Episodes</th>\n",
       "      <th>Members</th>\n",
       "      <th>Score</th>\n",
       "      <th>Users</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Description</th>\n",
       "      <th>Related</th>\n",
       "      <th>Characters</th>\n",
       "      <th>Voices</th>\n",
       "      <th>Staff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Mononoke Hime</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1</td>\n",
       "      <td>1019767</td>\n",
       "      <td>8.69</td>\n",
       "      <td>655726</td>\n",
       "      <td>51</td>\n",
       "      <td>99</td>\n",
       "      <td>i</td>\n",
       "      <td>[Adaptation: Mushishi, Sequel: Mushishi: Hiham...</td>\n",
       "      <td>[San, Ashitaka, Gozen, Eboshi, Kodama, Moro, Y...</td>\n",
       "      <td>[Ishida, Yuriko, Matsuda, Youji, Tanaka, Yuko,...</td>\n",
       "      <td>[[Suzuki, Toshio, Producer], [Miyazaki, Hayao,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Shigatsu wa Kimi no Uso</td>\n",
       "      <td>TV</td>\n",
       "      <td>22</td>\n",
       "      <td>1781722</td>\n",
       "      <td>8.69</td>\n",
       "      <td>1056993</td>\n",
       "      <td>52</td>\n",
       "      <td>22</td>\n",
       "      <td>n</td>\n",
       "      <td>[Adaptation: Haikyuu!!, Prequel: Haikyuu!!, Se...</td>\n",
       "      <td>[Miyazono, Kaori, Arima, Kousei, Sawabe, Tsuba...</td>\n",
       "      <td>[Taneda, Risa, Hanae, Natsuki, Sakura, Ayane, ...</td>\n",
       "      <td>[[Saitou, Shunsuke, Producer], [Fukushima, Yuu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Mushishi</td>\n",
       "      <td>TV</td>\n",
       "      <td>26</td>\n",
       "      <td>698732</td>\n",
       "      <td>8.68</td>\n",
       "      <td>222619</td>\n",
       "      <td>53</td>\n",
       "      <td>185</td>\n",
       "      <td>c</td>\n",
       "      <td>[Adaptation: Hajime no Ippo, Prequel: Hajime n...</td>\n",
       "      <td>[Ginko, Karibusa, Tanyuu, Nui, Adashino, Narra...</td>\n",
       "      <td>[Nakano, Yuto, Tsuzurahara, Miyu, Doi, Mika, U...</td>\n",
       "      <td>[[Cook, Justin, Producer], [Suzuki, Atsushi, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Haikyuu!! Second Season</td>\n",
       "      <td>TV</td>\n",
       "      <td>25</td>\n",
       "      <td>1131284</td>\n",
       "      <td>8.67</td>\n",
       "      <td>730913</td>\n",
       "      <td>54</td>\n",
       "      <td>85</td>\n",
       "      <td>t</td>\n",
       "      <td>[Adaptation: Kaguya-sama wa Kokurasetai: Tensa...</td>\n",
       "      <td>[Hinata, Shouyou, Kageyama, Tobio, Nishinoya, ...</td>\n",
       "      <td>[Murase, Ayumu, Ishikawa, Kaito, Okamoto, Nobu...</td>\n",
       "      <td>[[Morihiro, Fumi, Producer], [Matsushita, Keik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Hajime no Ippo: New Challenger</td>\n",
       "      <td>TV</td>\n",
       "      <td>26</td>\n",
       "      <td>226819</td>\n",
       "      <td>8.66</td>\n",
       "      <td>132302</td>\n",
       "      <td>55</td>\n",
       "      <td>787</td>\n",
       "      <td>i</td>\n",
       "      <td>[Adaptation: Natsume Yuujinchou, Prequel: Nats...</td>\n",
       "      <td>[Takamura, Mamoru, Makunouchi, Ippo, Aoki, Mas...</td>\n",
       "      <td>[Koyama, Rikiya, Kiyasu, Kohei, Takagi, Wataru...</td>\n",
       "      <td>[[Shishido, Jun, Director], [Nakajima, Toshihi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Howl no Ugoku Shiro</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1</td>\n",
       "      <td>1030428</td>\n",
       "      <td>8.66</td>\n",
       "      <td>709127</td>\n",
       "      <td>56</td>\n",
       "      <td>95</td>\n",
       "      <td>o</td>\n",
       "      <td>[Adaptation: Violet Evergarden, Side story: Vi...</td>\n",
       "      <td>[Howl, Hatter, Sophie, Calcifer, Turnip Head, ...</td>\n",
       "      <td>[Kimura, Takuya, Baisho, Chieko, Gashuin, Tats...</td>\n",
       "      <td>[[Suzuki, Toshio, Producer], [Ishii, Tomohiko,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Title   Type Episodes  Members Score    Users  \\\n",
       "50                   Mononoke Hime  Movie        1  1019767  8.69   655726   \n",
       "51         Shigatsu wa Kimi no Uso     TV       22  1781722  8.69  1056993   \n",
       "52                        Mushishi     TV       26   698732  8.68   222619   \n",
       "53         Haikyuu!! Second Season     TV       25  1131284  8.67   730913   \n",
       "54  Hajime no Ippo: New Challenger     TV       26   226819  8.66   132302   \n",
       "55             Howl no Ugoku Shiro  Movie        1  1030428  8.66   709127   \n",
       "\n",
       "   Rank Popularity Description  \\\n",
       "50   51         99           i   \n",
       "51   52         22           n   \n",
       "52   53        185           c   \n",
       "53   54         85           t   \n",
       "54   55        787           i   \n",
       "55   56         95           o   \n",
       "\n",
       "                                              Related  \\\n",
       "50  [Adaptation: Mushishi, Sequel: Mushishi: Hiham...   \n",
       "51  [Adaptation: Haikyuu!!, Prequel: Haikyuu!!, Se...   \n",
       "52  [Adaptation: Hajime no Ippo, Prequel: Hajime n...   \n",
       "53  [Adaptation: Kaguya-sama wa Kokurasetai: Tensa...   \n",
       "54  [Adaptation: Natsume Yuujinchou, Prequel: Nats...   \n",
       "55  [Adaptation: Violet Evergarden, Side story: Vi...   \n",
       "\n",
       "                                           Characters  \\\n",
       "50  [San, Ashitaka, Gozen, Eboshi, Kodama, Moro, Y...   \n",
       "51  [Miyazono, Kaori, Arima, Kousei, Sawabe, Tsuba...   \n",
       "52  [Ginko, Karibusa, Tanyuu, Nui, Adashino, Narra...   \n",
       "53  [Hinata, Shouyou, Kageyama, Tobio, Nishinoya, ...   \n",
       "54  [Takamura, Mamoru, Makunouchi, Ippo, Aoki, Mas...   \n",
       "55  [Howl, Hatter, Sophie, Calcifer, Turnip Head, ...   \n",
       "\n",
       "                                               Voices  \\\n",
       "50  [Ishida, Yuriko, Matsuda, Youji, Tanaka, Yuko,...   \n",
       "51  [Taneda, Risa, Hanae, Natsuki, Sakura, Ayane, ...   \n",
       "52  [Nakano, Yuto, Tsuzurahara, Miyu, Doi, Mika, U...   \n",
       "53  [Murase, Ayumu, Ishikawa, Kaito, Okamoto, Nobu...   \n",
       "54  [Koyama, Rikiya, Kiyasu, Kohei, Takagi, Wataru...   \n",
       "55  [Kimura, Takuya, Baisho, Chieko, Gashuin, Tats...   \n",
       "\n",
       "                                                Staff  \n",
       "50  [[Suzuki, Toshio, Producer], [Miyazaki, Hayao,...  \n",
       "51  [[Saitou, Shunsuke, Producer], [Fukushima, Yuu...  \n",
       "52  [[Cook, Justin, Producer], [Suzuki, Atsushi, P...  \n",
       "53  [[Morihiro, Fumi, Producer], [Matsushita, Keik...  \n",
       "54  [[Shishido, Jun, Director], [Nakajima, Toshihi...  \n",
       "55  [[Suzuki, Toshio, Producer], [Ishii, Tomohiko,...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another example\n",
    "dataset[50:56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed7762c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each row create a tsv file. Put len(dataset) instead of 5 in the for loop\n",
    "for i in range(5):\n",
    "    with open('anime_'+str(i)+'.tsv', 'wt') as file:\n",
    "        tsv_writer = csv.writer(file, delimiter='\\t')\n",
    "        # header\n",
    "        tsv_writer.writerow([x for x in dataset.columns]) \n",
    "        # columns\n",
    "        tsv_writer.writerow(x for x in dataset.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d9ca39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
